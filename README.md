# Boosting Techniques Assignment

## ğŸ“Œ Overview
This repository contains implementations of various **Boosting techniques** used in **Machine Learning**. It covers multiple algorithms like **AdaBoost, Gradient Boosting, XGBoost, LightGBM, and CatBoost** with practical examples and evaluations.

## ğŸš€ Implemented Techniques

### 1ï¸âƒ£ **AdaBoost**
- Train an **AdaBoost Classifier** on a sample dataset and print model accuracy.
- Train an **AdaBoost Regressor** and evaluate using **Mean Absolute Error (MAE)**.
- Analyze the effect of **different learning rates** on AdaBoost performance.
- Visualize **feature importance** using AdaBoost.

### 2ï¸âƒ£ **Gradient Boosting**
- Train a **Gradient Boosting Classifier** on the **Breast Cancer dataset** and print feature importance.
- Train a **Gradient Boosting Regressor** and evaluate using **R-Squared Score**.
- Plot **learning curves** to analyze model performance.
- Visualize the **ROC curve** for Gradient Boosting Classifier.

### 3ï¸âƒ£ **XGBoost**
- Train an **XGBoost Classifier** and compare accuracy with Gradient Boosting.
- Train an **XGBoost Regressor** and evaluate using **Mean Squared Error (MSE)**.
- Tune the **learning rate** using **GridSearchCV**.
- Train an **XGBoost Classifier** for **multi-class classification** and evaluate using **log-loss**.

### 4ï¸âƒ£ **CatBoost**
- Train a **CatBoost Classifier** and evaluate using **F1-Score**.
- Train a **CatBoost Classifier** on an **imbalanced dataset** and compare performance **with and without class weighting**.
- Plot the **confusion matrix** for a CatBoost model.

## ğŸ“‚ Structure
```
ğŸ“ boosting-techniques-assignment
â”‚â”€â”€ ğŸ“„ README.md (This file)
â”‚â”€â”€ ğŸ“„ adaboost_classifier.py
â”‚â”€â”€ ğŸ“„ adaboost_regressor.py
â”‚â”€â”€ ğŸ“„ gradient_boosting_classifier.py
â”‚â”€â”€ ğŸ“„ gradient_boosting_regressor.py
â”‚â”€â”€ ğŸ“„ xgboost_classifier.py
â”‚â”€â”€ ğŸ“„ xgboost_regressor.py
â”‚â”€â”€ ğŸ“„ catboost_classifier.py
â”‚â”€â”€ ğŸ“„ catboost_imbalanced.py
â”‚â”€â”€ ğŸ“„ utils.py (Helper functions)
â””â”€â”€ ğŸ“‚ datasets (Custom datasets if needed)
```

## ğŸ›  Installation
To run the code, install the required dependencies using:
```bash
pip install numpy pandas scikit-learn matplotlib seaborn xgboost catboost lightgbm
```

## ğŸ“Š Results & Analysis
- **Comparisons** between different boosting techniques.
- **Feature importance** visualizations.
- **Performance metrics** (Accuracy, Log-Loss, F1-Score, ROC Curves, etc.).

## ğŸ¤– Future Enhancements
- Implement **LightGBM** examples.
- Perform **hyperparameter tuning** for all models.
- Explore **Stacked Boosting** for better performance.

## ğŸ’¡ Contributing
Feel free to contribute by improving code, adding new boosting techniques, or optimizing hyperparameters. Fork this repo and submit a **Pull Request**!

## ğŸ“œ License
This project is licensed under the **MIT License**.

---
ğŸ“¢ **Follow & Star** â­ the repository if you find it helpful!

